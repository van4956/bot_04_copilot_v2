import logging

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥–≥–µ—Ä –º–æ–¥—É–ª—è
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
logger.info("–ó–∞–≥—Ä—É–∂–µ–Ω –º–æ–¥—É–ª—å: %s", __name__)

from icecream import ic
ic.configureOutput(includeContext=True, prefix=' >>> Debag >>> ')

import os
from openai import OpenAI, OpenAIError
import asyncio
from pathlib import Path

from aiogram import F, Router, Bot
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import Message
from aiogram.filters import  StateFilter, or_f
from aiogram.fsm.context import FSMContext
from aiogram.utils.i18n import gettext as _
from aiogram.utils.i18n import lazy_gettext as __
from common import keyboard
from filters.chat_type import ChatTypeFilter

# —Å–æ–∑–¥–∞–µ–º —Ä–æ—É—Ç–µ—Ä
llm_router = Router()
llm_router.message.filter(ChatTypeFilter(['private']))


API_GPT = os.getenv('API_GPT')

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è LLMs
class LLMs(StatesGroup):
    """–ö–ª–∞—Å—Å —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è LLMs"""
    dialog_start = State()
    dialog_sistem_promt = State()
    dialog_process = State()

# –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–∞—Ö
LLM = __("LLMs ü§ñ")
START_NEW_DIALOG = __("–ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ ü§ñ")
BACK_TO_MAIN = __("–ù–∞–∑–∞–¥ –Ω–∞ –≥–ª–∞–≤–Ω—É—é ‚Ü©Ô∏è")
FINISH_DIALOG = __("–ó–∞–∫–æ–Ω—á–∏—Ç—å –¥–∏–∞–ª–æ–≥")


@llm_router.message(StateFilter(None), or_f(F.text == LLM, F.text == START_NEW_DIALOG))
async def llm_dialog_start(message: Message, state: FSMContext):

    try:
        await message.answer(_("–í–≤–µ–¥–∏—Ç–µ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç"))
        await message.answer(_("–ù–∞–ø—Ä–∏–º–µ—Ä:\n\n<code>–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –¢–≤–æ–π —Ç–æ–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º. –û—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º–∏ –∏ –ø–æ–Ω—è—Ç–Ω—ã–º–∏.</code>"),
                             reply_markup=keyboard.get_keyboard(_("–°—Ä–∞–∑—É –∫ –∑–∞–ø—Ä–æ—Å—É ‚ñ∂Ô∏è"), _("–ù–∞–∑–∞–¥ –Ω–∞ –≥–ª–∞–≤–Ω—É—é ‚Ü©Ô∏è"),
                                                                sizes=(1, 1,),
                                                                placeholder='‚¨áÔ∏è'))
        await state.set_state(LLMs.dialog_start)

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞: %s", str(e))
        text = str(e)
        await message.answer(text,
                             reply_markup=keyboard.get_keyboard(_("–ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ ü§ñ"), _("–ù–∞–∑–∞–¥ –Ω–∞ –≥–ª–∞–≤–Ω—É—é ‚Ü©Ô∏è"),
                                                                sizes=(1, 1,),
                                                                placeholder='‚¨áÔ∏è'))

@llm_router.message(LLMs.dialog_start, or_f(F.text, F.voice))
async def llm_dialog_sistem_promt(message: Message, state: FSMContext, bot: Bot):
    model = "gpt-4o"
    await state.update_data(llm_model=model)
    sistem_promt = ('Answering Rules\n\n'
                    'Follow in the strict order:\n\n'
                    '1. USE the language of my message.\n'
                    '2. ONCE PER CHAT assign a real-world expert role to yourself before answering, e.g., "I will answer as a world-famous historical expert <detailed topic> with <most prestigious LOCAL topic REAL award>" or "I will answer as a world-famous <specific science> expert in the <detailed topic> with <most prestigious LOCAL topic award>" etc.\n'
                    '3. You MUST combine your deep knowledge¬†of the topic and¬†clear thinking to quickly and accurately decipher the answer step-by-step with CONCRETE details.\n'
                    '4. I am going to tip $1,000,000 for the best reply.\n'
                    '5. Your answer¬†is critical for my career.\n'
                    '6. Answer the question in a natural, human-like manner.\n'
                    '7. ALWAYS use an answering example for a first message structure.\n'
                    '8. Responses should be output without using Markdown formatting symbols such as hash marks (#) or asterisks (*).\n'
                    '9. Use only these HTML tags for formatting: <b></b>, <i></i>, <code></code>\n'
                    '10. DO NOT use any other HTML tags.\n\n'
                    'Answering in English example\n\n'
                    '<b>I will answer as the world-famous</b> "specific field" scientists with "most prestigious LOCAL award"\n'
                    '"Deep knowledge step-by-step answer, with CONCRETE details"'
                    )
    if message.text:
        text = message.text
    elif message.voice:
        # –°–æ–æ–±—â–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –æ –Ω–∞—á–∞–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        processing_msg = await message.answer("‚åõÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            voice = await bot.get_file(message.voice.file_id)

            if not voice.file_path:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è")

            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            voice_dir = Path("temp_voice")
            voice_dir.mkdir(exist_ok=True)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç—å –¥–ª—è —Ñ–∞–π–ª–∞
            voice_path = voice_dir / f"{message.voice.file_id}.ogg"

            # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
            await bot.download_file(voice.file_path, voice_path)
            logger.info("–°–∫–∞—á–∞–Ω —Ñ–∞–π–ª –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: %s", voice_path)

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI
            client = OpenAI(api_key=API_GPT)

            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ
            with open(voice_path, "rb") as audio_file:
                transcript = await asyncio.to_thread(client.audio.transcriptions.create,
                                                                    model="whisper-1",
                                                                    file=audio_file,
                                                                    language="ru"
                                                                    )

            text = transcript.text

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            await processing_msg.delete()
            await message.answer(f"üîç –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n\n<code>{text}</code>")

        except Exception as e:
            await processing_msg.delete()
            await message.answer(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è:\n{e}")
            logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: %s", str(e))
            return

        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if 'voice_path' in locals():
                try:
                    voice_path.unlink()
                except Exception as e:
                    logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: %s", str(e))

    try:
        if text == _("–°—Ä–∞–∑—É –∫ –∑–∞–ø—Ä–æ—Å—É ‚ñ∂Ô∏è"):
            messages_context = [{"role": "system", "content": sistem_promt}]
            await state.update_data(llm_messages_context=messages_context)
        else:
            text = text if text else ' '
            sistem_promt = str(sistem_promt) + '\n\n' + text
            messages_context = [{"role": "system", "content": sistem_promt}]
            await state.update_data(llm_messages_context=messages_context)

        await message.answer(text=_("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å"),
                            reply_markup=keyboard.get_keyboard(_("–ù–∞–∑–∞–¥ –Ω–∞ –≥–ª–∞–≤–Ω—É—é ‚Ü©Ô∏è"),
                                                                sizes=(1, 1,),
                                                                placeholder='‚¨áÔ∏è'))
        await state.set_state(LLMs.dialog_process)

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞: %s", str(e))
        text = f"Error: {str(e)}"
        await message.answer(text,
                             reply_markup=keyboard.get_keyboard(_("–ù–∞–∑–∞–¥ –Ω–∞ –≥–ª–∞–≤–Ω—É—é ‚Ü©Ô∏è"),
                                                                sizes=(1, 1,),
                                                                placeholder='‚¨áÔ∏è'))


@llm_router.message(LLMs.dialog_process, F.text == FINISH_DIALOG)
async def llm_dialog_finish(message: Message, state: FSMContext):
    await message.answer(_("–î–∏–∞–ª–æ–≥ –∑–∞–≤–µ—Ä—à–µ–Ω.\n–ß—Ç–æ –¥–∞–ª—å—à–µ?"),
                         reply_markup=keyboard.get_keyboard(_("–ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ ü§ñ"),
                                                   _("–ù–∞–∑–∞–¥ –Ω–∞ –≥–ª–∞–≤–Ω—É—é ‚Ü©Ô∏è"),
                                                    sizes=(1, 1,),
                                                    placeholder='‚¨áÔ∏è'))
    await state.update_data(llm_messages_context=None, llm_model=None)
    await state.set_state(None)


@llm_router.message(LLMs.dialog_process, or_f(F.text, F.voice))
async def llm_dialog_process(message: Message, state: FSMContext, workflow_data: dict, bot: Bot):
    user_id = message.from_user.id
    state_data = await state.get_data()
    model = state_data['llm_model']
    messages_context = state_data['llm_messages_context']

    if message.text:
        content = message.text
    elif message.voice:
        # –°–æ–æ–±—â–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –æ –Ω–∞—á–∞–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        processing_msg = await message.answer("‚åõÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            voice = await bot.get_file(message.voice.file_id)

            if not voice.file_path:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è")

            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            voice_dir = Path("temp_voice")
            voice_dir.mkdir(exist_ok=True)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç—å –¥–ª—è —Ñ–∞–π–ª–∞
            voice_path = voice_dir / f"{message.voice.file_id}.ogg"

            # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
            await bot.download_file(voice.file_path, voice_path)
            logger.info("–°–∫–∞—á–∞–Ω —Ñ–∞–π–ª –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: %s", voice_path)

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI
            client = OpenAI(api_key=API_GPT)

            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ
            with open(voice_path, "rb") as audio_file:
                transcript = await asyncio.to_thread(client.audio.transcriptions.create,
                                                                    model="whisper-1",
                                                                    file=audio_file,
                                                                    language="ru"
                                                                    )

            content = transcript.text

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            await processing_msg.delete()
            await message.answer(f"üîç –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n\n<code>{content}</code>")

        except Exception as e:
            await processing_msg.delete()
            await message.answer(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è:\n{e}")
            logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: %s", str(e))
            return

        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if 'voice_path' in locals():
                try:
                    voice_path.unlink()
                except Exception as e:
                    logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: %s", str(e))

    try:
        client = OpenAI(api_key=API_GPT)
        role = 'user'
        messages_context.append({"role": role, "content": content})

        try:
            response = client.chat.completions.create(model=model, messages=messages_context)
            content = response.choices[0].message.content
            messages_context.append({"role": "system", "content": content})
            await state.update_data(llm_messages_context=messages_context)
            answer = f"{model}\n\n{content}"

        except OpenAIError as e:
            logger.error("–û—à–∏–±–∫–∞: %s", str(e))
            answer = f"<code>{model}</code>\n\nError: {str(e)}"

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞: %s", str(e))
        answer = f"Connection error to LLM:\n\n{str(e)}"
        return

    # –æ–±—Ä–µ–∑–∞–µ–º –æ—Ç–≤–µ—Ç, –µ—Å–ª–∏ –æ–Ω –ø—Ä–µ–≤—ã—à–∞–µ—Ç 4096 —Å–∏–º–≤–æ–ª–∞
    if len(answer) > 4096:
        answer = answer[:4096] + "..."
    try:
        await message.answer(answer,
                             reply_markup=keyboard.get_keyboard(_("–ó–∞–∫–æ–Ω—á–∏—Ç—å –¥–∏–∞–ª–æ–≥"),
                                                            sizes=(1,),
                                                            placeholder=_('–í–≤–µ–¥–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å')))
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞: %s", str(e))
        await message.answer("Error: " + str(e))

    analytics = workflow_data['analytics']
    await analytics(user_id=user_id,
                    category_name="/expense",
                    command_name="/llm")

# # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
# @editor_router.message(~StateFilter(Editor.editor_wait_command), or_f(F.text, F.voice))
# async def editor_wait_text(message: Message, state: FSMContext, bot: Bot):
#     if message.text:
#         data = await state.get_data()
#         list_text = data.get('text',[])
#         list_text.append(message.text)
#         await state.update_data(text=list_text)
#         await message.answer(f"‚úçÔ∏è –¢—ã –Ω–∞–ø–∏—Å–∞–ª:\n\n<code>{message.text}</code>",
#                          reply_markup=keyboard.work_keyboard())
#         await state.set_state(Editor.editor_wait_command)
#         await asyncio.sleep(1)
#         await message.answer("–û–∂–∏–¥–∞—é –∫–æ–º–∞–Ω–¥—É ‚¨áÔ∏è")

#     elif message.voice:
#         # –°–æ–æ–±—â–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –æ –Ω–∞—á–∞–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
#         processing_msg = await message.answer("‚åõÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
#         try:
#             # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
#             voice = await bot.get_file(message.voice.file_id)

#             if not voice.file_path:
#                 raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è")

#             # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
#             voice_dir = Path("temp_voice")
#             voice_dir.mkdir(exist_ok=True)

#             # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç—å –¥–ª—è —Ñ–∞–π–ª–∞
#             voice_path = voice_dir / f"{message.voice.file_id}.ogg"

#             # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
#             await bot.download_file(voice.file_path, voice_path)
#             logger.info("–°–∫–∞—á–∞–Ω —Ñ–∞–π–ª –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: %s", voice_path)

#             # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI
#             # client = OpenAI(api_key=API_GPT)

#             # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ
#             with open(voice_path, "rb") as audio_file:
#                 transcript = await asyncio.to_thread(client.audio.transcriptions.create,
#                                                                     model="whisper-1",
#                                                                     file=audio_file,
#                                                                     language="ru"
#                                                                     )

#             transcribed_text = transcript.text

#             # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ FSM
#             data = await state.get_data()
#             list_text = data.get('text', [])
#             list_text.append(transcribed_text)
#             await state.update_data(text=list_text)

#             # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
#             await processing_msg.delete()
#             await message.answer(f"üîç –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n\n<code>{transcribed_text}</code>",
#                                 reply_markup=keyboard.work_keyboard())
#             await state.set_state(Editor.editor_wait_command)
#             await asyncio.sleep(1)
#             await message.answer("–û–∂–∏–¥–∞—é –∫–æ–º–∞–Ω–¥—É ‚¨áÔ∏è")

#         except Exception as e:
#             await processing_msg.delete()
#             await message.answer(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}",
#                                  reply_markup=keyboard.work_keyboard())
#             await state.set_state(Editor.editor_wait_command)
#             logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: %s", str(e))

#         finally:
#             # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
#             if 'voice_path' in locals():
#                 try:
#                     voice_path.unlink()
#                 except Exception as e:
#                     logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: %s", str(e))
import logging

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥–≥–µ—Ä –º–æ–¥—É–ª—è
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
logger.info("–ó–∞–≥—Ä—É–∂–µ–Ω –º–æ–¥—É–ª—å: %s", __name__)

from icecream import ic
ic.configureOutput(includeContext=True, prefix=' >>> Debag >>> ')

import os
from openai import OpenAI

from aiogram import F, Router
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import Message
from aiogram.filters import  StateFilter, or_f
from aiogram.fsm.context import FSMContext
from aiogram.utils.i18n import gettext as _
from aiogram.utils.i18n import lazy_gettext as __
from common import keyboard
from filters.chat_type import ChatTypeFilter

# —Å–æ–∑–¥–∞–µ–º —Ä–æ—É—Ç–µ—Ä
llm_router = Router()
llm_router.message.filter(ChatTypeFilter(['private']))


API_GPT = os.getenv('API_GPT')

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è LLMs
class LLMs(StatesGroup):
    """–ö–ª–∞—Å—Å —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è LLMs"""
    dialog_start = State()
    dialog_sistem_promt = State()
    dialog_process = State()

# –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–∞—Ö
LLM = __("LLMs ü§ñ")
START_NEW_DIALOG = __("–ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ ü§ñ")
BACK_TO_MAIN = __("–ù–∞–∑–∞–¥ –Ω–∞ –≥–ª–∞–≤–Ω—É—é ‚Ü©Ô∏è")
FINISH_DIALOG = __("–ó–∞–∫–æ–Ω—á–∏—Ç—å –¥–∏–∞–ª–æ–≥")


@llm_router.message(StateFilter(None), or_f(F.text == LLM, F.text == START_NEW_DIALOG))
async def llm_dialog_start(message: Message, state: FSMContext):

    try:
        await message.answer(_("–í–≤–µ–¥–∏—Ç–µ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç"))
        await message.answer(_("–ù–∞–ø—Ä–∏–º–µ—Ä:\n\n<code>–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –¢–≤–æ–π —Ç–æ–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º. –û—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º–∏ –∏ –ø–æ–Ω—è—Ç–Ω—ã–º–∏.</code>"),
                             reply_markup=keyboard.get_keyboard(_("–°—Ä–∞–∑—É –∫ –∑–∞–ø—Ä–æ—Å—É ‚ñ∂Ô∏è"), _("–ù–∞–∑–∞–¥ –Ω–∞ –≥–ª–∞–≤–Ω—É—é ‚Ü©Ô∏è"),
                                                                sizes=(1, 1,),
                                                                placeholder='‚¨áÔ∏è'))
        await state.set_state(LLMs.dialog_start)

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞: %s", str(e))
        text = str(e)
        await message.answer(text,
                             reply_markup=keyboard.get_keyboard(_("–ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ ü§ñ"), _("–ù–∞–∑–∞–¥ –Ω–∞ –≥–ª–∞–≤–Ω—É—é ‚Ü©Ô∏è"),
                                                                sizes=(1, 1,),
                                                                placeholder='‚¨áÔ∏è'))

@llm_router.message(LLMs.dialog_start, F.text)
async def llm_dialog_sistem_promt(message: Message, state: FSMContext):
    model = "gpt-4o"
    await state.update_data(llm_model=model)
    sistem_promt = ('Answering Rules\n\n'
                    'Follow in the strict order:\n\n'
                    '1. USE the language of my message.\n'
                    '2. ONCE PER CHAT assign a real-world expert role to yourself before answering, e.g., "I will answer as a world-famous historical expert <detailed topic> with <most prestigious LOCAL topic REAL award>" or "I will answer as a world-famous <specific science> expert in the <detailed topic> with <most prestigious LOCAL topic award>" etc.\n'
                    '3. You MUST combine your deep knowledge¬†of the topic and¬†clear thinking to quickly and accurately decipher the answer step-by-step with CONCRETE details.\n'
                    '4. I am going to tip $1,000,000 for the best reply.\n'
                    '5. Your answer¬†is critical for my career.\n'
                    '6. Answer the question in a natural, human-like manner.\n'
                    '7. ALWAYS use an answering example for a first message structure.\n'
                    '8. Responses should be output without using Markdown formatting symbols such as hash marks (#) or asterisks (*).\n'
                    '9. Use only these HTML tags for formatting: <b></b>, <i></i>, <code></code>\n'
                    '10. DO NOT use any other HTML tags.\n\n'
                    'Answering in English example\n\n'
                    '<b>I will answer as the world-famous</b> "specific field" scientists with "most prestigious LOCAL award"\n'
                    '"Deep knowledge step-by-step answer, with CONCRETE details"'
                    )

    text = message.text
    try:
        if text == _("–°—Ä–∞–∑—É –∫ –∑–∞–ø—Ä–æ—Å—É ‚ñ∂Ô∏è"):
            messages_context = [{"role": "system", "content": sistem_promt}]
            await state.update_data(llm_messages_context=messages_context)
        else:
            text = text if text else ' '
            sistem_promt = str(sistem_promt) + '\n\n' + text
            messages_context = [{"role": "system", "content": sistem_promt}]
            await state.update_data(llm_messages_context=messages_context)

        await message.answer(text=_("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å"),
                            reply_markup=keyboard.get_keyboard(_("–ù–∞–∑–∞–¥ –Ω–∞ –≥–ª–∞–≤–Ω—É—é ‚Ü©Ô∏è"),
                                                                sizes=(1, 1,),
                                                                placeholder='‚¨áÔ∏è'))
        await state.set_state(LLMs.dialog_process)

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞: %s", str(e))
        text = f"Error: {str(e)}"
        await message.answer(text,
                             reply_markup=keyboard.get_keyboard(_("–ù–∞–∑–∞–¥ –Ω–∞ –≥–ª–∞–≤–Ω—É—é ‚Ü©Ô∏è"),
                                                                sizes=(1, 1,),
                                                                placeholder='‚¨áÔ∏è'))

@llm_router.message(LLMs.dialog_process, F.text == FINISH_DIALOG)
async def llm_dialog_finish(message: Message, state: FSMContext):
    await message.answer(_("–î–∏–∞–ª–æ–≥ –∑–∞–≤–µ—Ä—à–µ–Ω.\n–ß—Ç–æ –¥–∞–ª—å—à–µ?"),
                         reply_markup=keyboard.get_keyboard(_("–ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ ü§ñ"),
                                                   _("–ù–∞–∑–∞–¥ –Ω–∞ –≥–ª–∞–≤–Ω—É—é ‚Ü©Ô∏è"),
                                                    sizes=(1, 1,),
                                                    placeholder='‚¨áÔ∏è'))
    await state.update_data(llm_messages_context=None, llm_model=None)
    await state.set_state(None)

@llm_router.message(LLMs.dialog_process, F.text)
async def llm_dialog_process(message: Message, state: FSMContext, workflow_data: dict):
    user_id = message.from_user.id
    state_data = await state.get_data()
    model = state_data['llm_model']
    messages_context = state_data['llm_messages_context']

    try:
        client = OpenAI(api_key=API_GPT)
        role = 'user'
        content = message.text
        messages_context.append({"role": role, "content": content})

        try:
            response = client.chat.completions.create(model=model, messages=messages_context)
            content = response.choices[0].message.content
            messages_context.append({"role": "system", "content": content})
            await state.update_data(llm_messages_context=messages_context)
            answer = f"{model}\n\n{content}"

        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞: %s", str(e))
            answer = f"<code>{model}</code>\n\nError: {str(e)}"

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞: %s", str(e))
        answer = f"Connection error to LLM:\n\n{str(e)}"

    # –æ–±—Ä–µ–∑–∞–µ–º –æ—Ç–≤–µ—Ç, –µ—Å–ª–∏ –æ–Ω –ø—Ä–µ–≤—ã—à–∞–µ—Ç 4096 —Å–∏–º–≤–æ–ª–∞
    if len(answer) > 4096:
        answer = answer[:4096] + "..."
    try:
        await message.answer(answer,
                             reply_markup=keyboard.get_keyboard(_("–ó–∞–∫–æ–Ω—á–∏—Ç—å –¥–∏–∞–ª–æ–≥"),
                                                            sizes=(1,),
                                                            placeholder=_('–í–≤–µ–¥–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å')))
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞: %s", str(e))
        await message.answer("Error: " + str(e))

    analytics = workflow_data['analytics']
    await analytics(user_id=user_id,
                    category_name="/expense",
                    command_name="/llm")
